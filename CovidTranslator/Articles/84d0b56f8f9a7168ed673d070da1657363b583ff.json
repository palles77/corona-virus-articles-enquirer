{
    "paper_id": "84d0b56f8f9a7168ed673d070da1657363b583ff",
    "metadata": {
        "title": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network",
        "authors": [
            {
                "first": "Asmaa",
                "middle": [],
                "last": "Abbas",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Assiut University",
                    "location": {
                        "settlement": "Assiut",
                        "country": "Egypt"
                    }
                },
                "email": ""
            },
            {
                "first": "Mohammed",
                "middle": [
                    "M"
                ],
                "last": "Abdelsamea",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Assiut University",
                    "location": {
                        "settlement": "Assiut",
                        "country": "Egypt"
                    }
                },
                "email": "*mohammed.abdelsamea@bcu.ac.uk"
            },
            {
                "first": "Mohamed",
                "middle": [],
                "last": "Medhat Gaber",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Birmingham City University",
                    "location": {
                        "settlement": "Birmingham",
                        "country": "UK"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Chest X-ray is the first imaging technique that plays an important role in the diagnosis of COVID-19 disease. Due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks (CNN s) for image recognition and classification. However, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. In this paper, we validate and adopt our previously developed CNN, called Decompose, Transfer, and Compose (DeTraC ), for the classification of COVID-19 chest X-ray images. DeTraC can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. The experimental results showed the capability of DeTraC in the detection of COVID-19 cases from a comprehensive image dataset collected from several hospitals around the world. High accuracy of 95.12% (with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of 93.36%) was achieved by DeTraC in the detection of COVID-19 X-ray images from normal, and severe acute respiratory syndrome cases. 12 disease within computed tomography (CT ). In [3], a modified version of ResNet-50 13 pre-trained network has been provided to classify CT images into three classes: healthy, 14 COVID-19 and bacterial pneumonia. Chest x-ray images (CXR) were used in [4] by a 15 CNN constructed based on various ImageNet pre-trained models to extract the high 16",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Diagnosis of COVID-19 is typically associated with both the symptoms of pneumonia 2 and Chest X-ray tests. Chest X-ray is the first imaging technique that plays an 3 important role in the diagnosis of COVID-19 disease. Fig. 1 shows a negative example 4 of a normal chest x-ray, a positive one with COVID-19, and a positive one with the 5 severe acute respiratory syndrome (SARS). 6 In the last few months, World Health Organization (WHO) has declared that a new 7 virus called COVID-19 has been spread aggressively in several countries around the 8 world [1] . Fast detection of the COVID-19 can be contributed to control the spread of 9 the disease. One of the most successful algorithms that have been proved its ability to 10 diagnosis medical images with high accuracy is convolution neural network (CNN ). For 11 example, in [2] , a CNN was applied based on Inception network to detect COVID-19 level features. Those features were fed into a Support Vector Machine SVM as a 17 machine learning classifier in order to detect the COVID-19 cases. Moreover, in [5] , a 18 CNN architecture called COVID-Net based on transfer learning was applied to classify 19 the CXR images into four classes: normal, bacterial infection, non-COVID and 20 COVID-19 viral infection. 21 Several classical machine learning approaches have been previously used for 22 automatic classification of digitised chest images [6, 7] . For instance, in [8] , three 23 statistical features were calculated from lung texture to discriminate between malignant 24 and benign lung nodules using a support vector machine classifier. A grey-level 25 co-occurrence matrix method was used with Backpropagation Network [9] to classify 26 images from being normal or cancerous. With the availability of enough annotated 27 images, deep learning approaches [10, 11] have demonstrated their superiority over the 28 classical machine learning approaches. CNN architecture is one of the most popular 29 deep learning approaches with superior achievements in the medical imaging domain [12] . 30 The primary success of CNN is due to its ability to learn features automatically from 31 domain-specific images, unlike the classical machine learning methods. The popular 32 strategy for training CNN architecture is to transfer learned knowledge from a 33 pre-trained network that fulfilled one task into a new task [13] . This method is faster 34 and easy to apply without the need for a huge annotated dataset for training; therefore 35 many researchers tend to apply this strategy especially with medical imaging.",
            "cite_spans": [
                {
                    "start": 555,
                    "end": 558,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 830,
                    "end": 833,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1062,
                    "end": 1065,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1400,
                    "end": 1403,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1404,
                    "end": 1406,
                    "text": "7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1426,
                    "end": 1429,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1682,
                    "end": 1685,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1818,
                    "end": 1822,
                    "text": "[10,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1823,
                    "end": 1826,
                    "text": "11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 2043,
                    "end": 2047,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 2050,
                    "end": 2052,
                    "text": "30",
                    "ref_id": null
                },
                {
                    "start": 2370,
                    "end": 2374,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 219,
                    "end": 225,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": ""
        },
        {
            "text": "Class decomposition [14] has been proposed with the aim of enhancing low variance 37 classifiers facilitating more flexibility to their decision boundaries. In this paper, we 38 adopt and validate DeTraC [15] for the classification of COVID-19 in chest x-ray images 39 1 . This is by adding a class decomposition layer to the pre-trained models. The class 40 decomposition layer aims to partition each class within the image dataset into several 41 sub-classes and then assign new labels to the new set, where each subset is treated as an 42 independent class, then those subsets are assembled back to produce the final 43 predictions. For the classification performance evaluation, we used images of chest x-ray 44 collected from several hospitals and institutions. The dataset provides complicated Then we apply the class-decomposition layer of DeTraC to simplify the local structure 52 of the data distribution. In the second phase, the training is accomplished using a 53 sophisticated gradient descent optimisation method. Finally, we use the pre-trained CNN model using the collected chest X-ray image dataset. We used the 64 off-the-shelf CNN features of pre-trained models on ImageNet (where the training is 65 accomplished only on the final classification layer) to construct the image feature space. 66 However, due to the high dimensionality associated with the images, we applied PCA to 67 project the high-dimension feature space into a lower-dimension, where highly 68 correlated features were ignored. This step is important for the class decomposition to 69 produce more homogeneous classes, reduce the memory requirements, and improve the 70 efficiency of the framework.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 24,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 204,
                    "end": 208,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "36"
        },
        {
            "text": "March 30, 2020 3/9",
            "cite_spans": [],
            "ref_spans": [],
            "section": "71"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "71"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint Now assume that our feature space (PCA's output) is represented by a 2-D matrix 73 (denoted as dataset A): A = {a 1 , a 2 , . . . . . . .., a n } , where n is the number of images, 74 a i = (a i1 , a i2 , . . . .., a in ), and L is a class category. A and L can be rewritten as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "71"
        },
        {
            "text": "where \u03ba is the number of classes and m is the number of features. For class 76 decomposition, we used k-means clustering [16] to further divide each class into 77 homogeneous sub-classes, where each pattern in the original class L is assigned to a 78 class label associated with the nearest centroid based on the squared euclidean distance 79 (SED):",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 125,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "71"
        },
        {
            "text": "where centroids are denoted as c j .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "71"
        },
        {
            "text": "Accordingly, the relationship between dataset A and B can be mathematically 82 described as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "81"
        },
        {
            "text": "where the number of instances in A is equal to B while C is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "81"
        },
        {
            "text": "Also, the feature space of both dataset A and B can be illustrated as: freezing the weights of low-level layers and update weighs of high-level layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "81"
        },
        {
            "text": "For fine-tuning the parameters, the learning rate for all the CNN layers was fixed to 90 0.0001 except for the last fully connected layer (was 0.01), the min batch size was 64",
            "cite_spans": [],
            "ref_spans": [],
            "section": "89"
        },
        {
            "text": "March 30, 2020 4/9",
            "cite_spans": [],
            "ref_spans": [],
            "section": "91"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "91"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20047456 doi: medRxiv preprint with minimum 256 epochs, 0.001 was set for the weight decay to prevent the overfitting 92 through training the model, and the momentum value was 0.9. With the limited 93 availability of training data, stochastic gradient descent (SGD) can heavily be 94 fluctuating the objective/loss function and hence overfitting can occur. To improve 95 convergence and overcome overfitting, the mini-batch of stochastic gradient descent 96 (mSGD) was used to minimise the objective function, E(\u00b7), with cross-entropy loss",
            "cite_spans": [],
            "ref_spans": [],
            "section": "91"
        },
        {
            "text": "where x j is the set of input images in the training, y j is the ground truth labels 98 while z(\u00b7) is the predicted output from a softmax function. functions and three different kernel filters. We adopted the last fully connected layer 122 into three classes and initialised the weight parameters for our specific classification 123 task. Secondly, we used k-means clustering [16] to apply the decomposition step and 124 divide each class into two subclasses (i.e. k = 2). Finally, we assigned the new labels to 125 the new sets, where each subset is treated as an independent class. More precisely, we 126 constructed a new dataset (we called dataset B) with six classes (norm 1 , norm 2 , 127 COV ID19 1 ,COV ID19 2 , SARS 1 , and SARS 2 ), see Table 1 .",
            "cite_spans": [
                {
                    "start": 376,
                    "end": 380,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [
                {
                    "start": 747,
                    "end": 754,
                    "text": "Table 1",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "91"
        },
        {
            "text": "March 30, 2020 5/9",
            "cite_spans": [],
            "ref_spans": [],
            "section": "128"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "128"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "128"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "128"
        },
        {
            "text": "between the different classes in the dataset. CNN s can provide an effective and robust 162 solution for the detection of the COVID-19 cases from chest X-ray CXR images and this 163 can be contributed to control the spread of the disease. Here, we adopt and validate our 164 previously developed deep convolutional neural network, we called DeTraC, to deal with 165 such a challenging problem by exploiting the advantages of class decomposition within 166 the CN N s for image classification. DeTraC achieved high accuracy of 95.12% with 167 ResNet on CXR images. ",
            "cite_spans": [
                {
                    "start": 538,
                    "end": 541,
                    "text": "167",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "128"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Coronavirus disease 2019 ( COVID-19): situation report, 51",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19). medRxiv",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep learning Enables Accurate Diagnosis of Novel Coronavirus (COVID-19) with CT images. medRxiv",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Detection of Coronavirus Disease (COVID-19) Based on Deep Features",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "K"
                    ],
                    "last": "Sethy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Behera",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Artificial neural network-based classification system for lung nodules on computed tomography scans",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Dand\u0131l",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ek\u015fi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "\u00d6zkan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kurt\u00f6k",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Canan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "6th International conference of soft computing and pattern recognition (SoCPaR)",
            "volume": "",
            "issn": "",
            "pages": "382--386",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Lung cancer classification using neural networks for CT images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kuruvilla",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Gunavathi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "113",
            "issn": "",
            "pages": "202--209",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Lung cancer detection using fuzzy auto-seed cluster means morphological segmentation and SVM classifier",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Manikandan",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Bharathi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of medical systems",
            "volume": "40",
            "issn": "7",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Lung tumour detection and classification using EK-Mean clustering",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sangamithraa",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Govindaraju",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 International Conference on Wireless Communications",
            "volume": "",
            "issn": "",
            "pages": "2201--2206",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Lung pattern classification for interstitial lung diseases using a deep convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Anthimopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Christodoulidis",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ebner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Christe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mougiakakou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE transactions on medical imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1207--1216",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Computer aided lung cancer diagnosis with deep learning algorithms",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Medical imaging 2016: computer-aided diagnosis",
            "volume": "9785",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "nature",
            "volume": "521",
            "issn": "7553",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A survey on transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Transactions on knowledge and data engineering",
            "volume": "22",
            "issn": "10",
            "pages": "1345--1359",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Class decomposition via clustering: a new framework for low-variance classifiers",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vilalta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Achari",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "F"
                    ],
                    "last": "Eick",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Third IEEE International Conference on Data Mining",
            "volume": "",
            "issn": "",
            "pages": "673--676",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "DeTraC: Transfer Learning of Class Decomposed Medical Images in Convolutional Neural Networks. under review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Abbas",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Abdelsamea",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Gaber",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Top 10 algorithms in data mining. Knowledge and information systems",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Quinlan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Motoda",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "14",
            "issn": "",
            "pages": "1--37",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Selecting and interpreting measures of thematic classification accuracy. Remote sensing of Environment",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "V"
                    ],
                    "last": "Stehman",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "",
            "volume": "62",
            "issn": "",
            "pages": "77--89",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Lung Segmentation in Chest Radiographs Using Anatomical Atlases With Nonrigid Registration",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Palaniappan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Musco",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "33",
            "issn": "2",
            "pages": "577--590",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2013.2290491"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Automatic Tuberculosis Screening Using Chest Radiographs",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karargyris",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Folio",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Siegelman",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Callaghan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "33",
            "issn": "2",
            "pages": "233--245",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2013.2284099"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "COVID-19 image data collection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Examples of a) normal, b) COVID-19, and c) SARS chest x-ray images.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Decompose, Transfer, and Compose (DeTraC ) model for the classification of chest X-ray images.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "54class-composition layer of DeTraC to refine the final classification of the images. As55 illustrated in Fig. 2, class decomposition and composition components are added 56 respectively before and after knowledge transformation from an ImageNet pre-trained 57 CNN model. The class decomposition component aiming at partitioning each class 58 within the image dataset into k sub-classes, where each subclass is treated 59 independently. Then those sub-classes are assembled back using the class-composition 60 component to produce the final classification of the original image dataset. 61 Deep feature extraction 62 A shallow-tuning mode was used during the adaptation and training of an ImageNet63",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "the class decomposition layer of DeTrac, we divide each class within the image 101 dataset into several sub-classes, where each subclass is treated as a new independent 102 class. In the composition phase, those sub-classes are assembled back to produce the 103 final prediction based on the original image dataset. For performance evaluation, we 104 adopted Accuracy (ACC), Specificity (SP) and Sensitivity (SN) metrics from the 105confusion matrix (as pointed out in[18]). our framework we used a combination of two datasets. We used 80 samples of normal 109 CXRs (with 4020 \u00d7 4892 pixels) from the Japanese Society of Radiological Technology 110 (JSRT )[19,20] and another imageset contains 105 and 11 samples of COVID-19 and 111 SARS (with 4248 \u00d7 3480 pixels), respectively, from[21]. We applied different data112 augmentation techniques to generate more samples such as: flipping up/down and 113 right/left, translation and rotation using random five different angles. This process 114 resulted in a total of 1764 samples. Also, a histogram modification technique was 115 applied to enhance the contrast of each image. 116 0.1 Class decomposition based on deep features 117 We used AlexNet [22] pre-trained network based on shallow learning mode to extract 118 discriminative features of the three original classes. AlexNet is composed of 5 119 convolutional layers to represent learned features, 3 fully connected layers for the 120 classification task. AlexNet uses 3 \u00d7 3 max-pooling layers with ReLU activation 121",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The learning curve accuracy and error obtained by ResNet18 pre-trained network.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The ROC analysis curve by training DeTraC model based on ResNet pre-",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "paper, we used DeTraC deep CNN architecture that relies on a class 170 decomposition approach for the classification of COVID-19 images in a comprehensive 171 dataset of chest X-ray images. DeTraC showed effective and robust solutions for the 172 classification of COVID-19 cases and its ability to cope with data irregularity and the 173 limited number of training images too.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": ")",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Samplesimage size of 224 \u00d7 224 and achieved an effective performance with 95.12% of accuracy.136   The last fully-connected layer was changed into the new task to classify six classes. The 137 learning rate for all the CNN layers was fixed to 0.0001 except for the last fully DeTraC-ResNet18 was trained based on deep learning mode. For performance evaluation, we adopted some metrics from the confusion matrix such as accuracy, sensitivity, specificity, and precision. The results were reported and summarised in table 2.We plot the learning curve accuracy and loss between training and test as shown in 146Fig 3. Also, the Area Under the receiver curve (AUC) was computed as shown in Fig 4. 147 To demonstrate the robustness of DeTraC-ResNet18 in the classification of COVID-19 images, we compare it with ResNet18 using the same settings. ResNet18 149 achieved accuracy of 92.5%, sensitivity of 65.01%, specificity of 94.3%, and precision of 150 94.5%.Training CNN s can be accomplished using two different strategies. They can be used as 153 an end-to-end network, where an enormous number of annotated images must be provided (which is impractical in medical imaging). Alternatively, transfer learning usually provides an effective solution with the limited availability of annotated images 156 by transferring knowledge from pre-trained CNN s (that have been learned from a",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}