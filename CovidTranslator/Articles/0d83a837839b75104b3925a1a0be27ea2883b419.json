{
    "paper_id": "0d83a837839b75104b3925a1a0be27ea2883b419",
    "metadata": {
        "title": "Estimating epidemic exponential growth rate and basic reproduction number",
        "authors": [
            {
                "first": "Junling",
                "middle": [],
                "last": "Ma",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Victoria",
                    "location": {
                        "postCode": "V8W 2Y2",
                        "settlement": "Victoria",
                        "region": "BC",
                        "country": "Canada"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The initial exponential growth rate of an epidemic is an important measure of the severeness of the epidemic, and is also closely related to the basic reproduction number. Estimating the growth rate from the epidemic curve can be a challenge, because of its decays with time. For fast epidemics, the estimation is subject to over-fitting due to the limited number of data points available, which also limits our choice of models for the epidemic curve. We discuss the estimation of the growth rate using maximum likelihood method and simple models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "This is a series of lecture notes for a summer school in Shanxi University, China in 2019. The contents are based on Ma et al. (Ma, Dushoff, Bolker, & Earn, 2013) . We will study the initial exponential growth rate of an epidemic in Section 1, the relationship between the exponential growth rate and the basic reproduction number in Section 2, an introduction to the least square estimation and its limitations in Section3, an introduction to the maximum likelihood estimation in Section 4, and the maximum likelihood estimation of the growth rate in Section 5.",
            "cite_spans": [
                {
                    "start": 127,
                    "end": 162,
                    "text": "(Ma, Dushoff, Bolker, & Earn, 2013)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Epidemic curves are time series data of the number of cases per unit time. Common choices for the time unit include a day, a week, a month, etc. It is an important indication for the severeness of an epidemic as a function of time. For example, Fig. 1 shows the cumulative number of Ebola cases during the 2014e16 Ebola outbreak in western Africa. The cumulative cases during the initial growth phase form an approximately linear relationship with time in log-linear scale. Thus, in linear scale, the number of deaths increases exponentially with time. The mortality curve (the number of deaths per unit time) shows a similar pattern, as demonstrated by the daily influenza deaths in Philadelphia during the 1918 influenza pandemic shown in Fig. 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 245,
                    "end": 251,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 741,
                    "end": 747,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "In fact, most epidemics grow approximately exponentially during the initial phase of an epidemic. This can be illustrated by the following examples. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "where S is the fraction of susceptible individuals, I is the fraction of infectious individuals, and R is the fraction of recovered individuals; b is the transmission rate per infectious individual, and g is the recovery rate, i.e., the infectious period is exponentially distributed with a mean 1=g. Linearize about the disease-free equilibrium (DFE) \u00f01; 0; 0\u00de, dI dt z\u00f0b \u00c0 g\u00deI:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "(2) Thus, if b \u00c0 g > 0, then I\u00f0t\u00de grows exponentially about the DFE. In addition, initially, Sz1, thus, the incidence rate (number of new cases per unit time) C \u00bc bSI also increases exponentially.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "It is similar for an Susceptible-Exposed-Infectious-Recovered (SEIR) model, as illustrated by the following example.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "Example 2. Lets consider an SEIR model:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "where E is the fraction of latent individuals (infected but not infectious), s the rate that latent individuals leaving the class, i.e; , the mean latent period is exponentially distributed with mean 1=s; S, I, R, b and g are similarly defined as in Example 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "Again, \u00f01; 0; 0; 0\u00de is a disease free equilibrium representing a completely susceptible population. Linearize about this equilibrium, the equations for E and I are decoupled, and become dE dt",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "Note that the Jacobian matrix J \u00bc \u00c0s b s \u00c0g ! has two real eigenvalues, namely, l 1 \u00bc \u00c0\u00f0s \u00fe g\u00de \u00fe ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \u00f0s \u00c0 g\u00de 2 \u00fe 4sb q 2 ; l 2 \u00bc \u00c0\u00f0s \u00fe g\u00de \u00c0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \u00f0s \u00c0 g\u00de 2 \u00fe 4sb q 2 :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "Thus, about the DFE, the solution of the model is asymptotically exponential with a rate l 1 . Similar to Example 1, the incidence rate also grows exponentially initially. In general, suppose the infection states of an individual can be characterized by the following vector \u00f0 S ! ; I ! \u00de, where S ! represents multiple susceptible states, and I ! represents multiple infectious (or latent) states. We also use S ! and I ! represent the number of individuals in each state. Also assume that the epidemic can be modeled by the following generic system",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "\u00de is a DFE, and the initial number of infectious individuals I ! \u00f00\u00de is very small, then, initially, the dynamics of I is governed by the following linearized system",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "If the DEF is unstable, then I\u00f0t\u00de grows asymptotically exponentially.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "2. The exponential growth rate and the basic reproduction number",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "The exponential growth rate is, by itself, an important measure for the speed of spread of an infectious disease. It being zero is, like the basic reproduction number R 0 \u00bc 1, a disease threshold. The disease can invade a population if the growth rate is positive, and cannot invade (with a few initially infectious individuals) if it is negative. In fact, it can be used to infer R 0 .There are two approaches to infer R 0 from the exponential growth rate, a parametric one, and a non-parametric one.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Epidemic exponential growth rate"
        },
        {
            "text": "For the parametric approach, we need an underlying model that gives both the growth rate and R 0 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The parametric approach"
        },
        {
            "text": "Example 3. Consider the SIR model (1) in Example 1. Note that \u00f01; 0; 0\u00de is an disease free equilibrium, representing a completely susceptible population. As we discussed above, the exponential growth rate is l \u00bc b \u00c0 g. Note that the basic reproduction number is R 0 \u00bc b=g . If, for example, g is estimated independently to l, then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The parametric approach"
        },
        {
            "text": "Lets look at a more complicated example. express b in terms of l and substitute it into R 0 , then",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The parametric approach"
        },
        {
            "text": "Thus, if the mean infectious period 1=g and the mean latent period 1=s can be independently estimated on l, then R 0 can be inferred from l.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The parametric approach"
        },
        {
            "text": "Typically, for an epidemic model that contains a single transmission rate b, if all other parameters can be estimated independently to the exponential growth rate l, then l determines b, and thus determines R 0 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The parametric approach"
        },
        {
            "text": "Models can be overly simplified for mathematical tractability. For example, Both the SIR model in Example 1 and the SEIR model in Example 2 assume exponentially distributed infectious period. However, the infectious period and the latent period are mostly likely not exponential. Wallinga and Lipsitch (Wallinga & Lipsitch, 2006 ) developed a non-parametric method to infer the basic reproduction number from the exponential growth rate without assuming a model. Let h\u00f0a\u00de be the probability that a random individual remain infectious a time units after being infected (i.e., a is the infection age); b\u00f0a\u00de is the rate of transmission at the infection age a. Then, t\u00f0a\u00de \u00bc h\u00f0a\u00deb\u00f0a\u00de is the transmissibility of a random infectious individual at the infection age a, assuming that the whole population is susceptible. Thus,",
            "cite_spans": [
                {
                    "start": 280,
                    "end": 328,
                    "text": "Wallinga and Lipsitch (Wallinga & Lipsitch, 2006",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "In addition, we assume that the population is randomly mixed, i.e., every pair of individuals have identical rate of contact. Let c\u00f0t\u00dedt be the number of new infections during the time interval \u00bdt;t \u00fe dt, that is, c\u00f0t\u00de is the incidence rate, and S\u00f0t\u00de be the average susceptibility of the population, i.e., the expected susceptibility of a randomly selected individual. In addition, new infections at time t is the sum of all infections caused by infectious individuals infected a time unit ago (i.e., at time t \u00c0 a) if they remain infectious at time t (with an infectious age a) and their contact is susceptible. That is,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "and thus c\u00f0t\u00de \u00bc S\u00f0t\u00de",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "To compute R 0 , we need to normalize t\u00f0a\u00de as a probability density function,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Note that w\u00f0a\u00deda is the probability that a secondary infection occurs during the infection age interval \u00bda; a \u00fe da. That is, w\u00f0a\u00de is the probability density function of the generation time, i.e., the time from being infected to generate a secondary infection. This generation time is also called the serial interval. With the serial interval distribution w\u00f0t\u00de,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "This means that the c\u00f0t\u00de is only determined by R 0 , w\u00f0t\u00de and S\u00f0t\u00de. At the beginning of an epidemic, where the epidemic grows exponentially (with an exponential growth rate l), S\u00f0t\u00dez1 and c\u00f0t\u00de \u00bc c 0 e lt where c 0 is the initial number of cases at",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "where M\u00f0x\u00de \u00bc R \u221e 0 e xa w\u00f0a\u00deda is the moment generating function of the serial time distribution w\u00f0a\u00de. Equation (5) links the exponential growth rate to the basic reproduction number though the serial interval distribution only. That is, if we can estimate the serial interval distribution and the exponential growth rate independently, that we can infer the basic reproduction number.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Note that the serial interval distribution w\u00f0t\u00de can be estimated independently to the exponential growth rate. For example, it can be estimated empirically using contact tracing. Alternatively, one can also assume an epidemic model. Here we discuss a few simple examples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Example 5. Consider an SIR model. Let F\u00f0a\u00de be the cumulative distribution function of the infectious period, and a constant transmission rate b. The probability that an infected individual remains infectious a time units after being infected is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "and thus the transmissibility is t\u00f0a\u00de \u00bc b\u00bd1 \u00c0 F\u00f0a\u00de; and the serial interval distribution is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "where m is the mean infectious period. For the special case that the infectious period is exponentially distributed with a rate g,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "i.e., F\u00f0a\u00de \u00bc 1 \u00c0 e \u00c0ga , this model becomes Model (1). Then the density function of serial interval distribution is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "which is identical to the density function of infectious period distribution. The moment generating function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Note that the exponential growth rate is l \u00bc b \u00c0 g, then",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Lets consider a more complex example with multiple infected states.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Example 6. Consider an SEIR model with a constant transmission rate b. Let F\u00f0a\u00de and G\u00f0a\u00de be the cumulative distribution functions of the infectious period and the latent period, respectively. Given the latent period T L \u00bc [ a, the probability that an infectious individual is infectious a time units after being infected is 1 \u00c0 F\u00f0a \u00c0 [\u00de:Thus,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "Hence, the serial interval distribution is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "For the special case that the latent period is exponentially distributed with a rate s (i.e., F\u00f0a\u00de \u00bc 1 \u00c0 e \u00c0ga ) and the latent period is exponentially distributed with a rate s (i.e., G\u00f0a\u00de \u00bc 1 \u00c0 e \u00c0sa ), this model becomes Model (3), and w\u00f0a\u00de \u00bc gse \u00c0ga Z a 0 e \u00f0g\u00c0s\u00des ds \u00bc \u00f0ge \u00c0ga \u00de\u00c3\u00f0se \u00c0sa \u00de:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "That is, if both distributions are exponential, the serial interval distribution is the convolution of the latent period distribution and the infectious period distribution. In this case, the basic reproduction number is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "where M I \u00f0x\u00de and M L \u00f0x\u00de are the moment generating functions of the infectious period and latent period, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The non-parametric approach"
        },
        {
            "text": "In Equation (4), R \u00f0t\u00de \u00bc R 0 S\u00f0t\u00de is the reproduction number, and thus this equation can be used to estimate the production number at any time t during the epidemic given the incidence curve c\u00f0t\u00de, namely,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Remark"
        },
        {
            "text": "This is similar to, but different from, the nonparametric method developed by Wallingua and Teunis (Wallinga & Teunis, 2004) .",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 124,
                    "text": "(Wallinga & Teunis, 2004)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Remark"
        },
        {
            "text": "The least squares method is one of the most commonly used methods for parameter estimation in mathematical biology. This method is in fact a mathematical method. For a family of curves f \u00f0t; q ! \u00de, where q ! 2R m is a vector of parameters of the family, this method finds the curve f \u00f0t; b q\u00de in the family that minimizes the distance between the curve and a set of points",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": ", and x ! be the Euclidean norm in R n , then the mathematical formulation of the least squares method is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "where argmin gives the parameter q ! that minimizes the objective function. For our purpose, the observations f\u00f0t i ; x i \u00deg n\u00c01 i\u00bc0 is the epidemic curve, i.e., x 0 is the number of initially observed cases, and x i is the number of new cases during the time interval \u00f0t i\u00c01 ; t 1 . We aim to find an exponential function f \u00f0t; c 0 ; l\u00de \u00bc c 0 e lt that minimizes its distance to the epidemic curve, i.e., the parameters q \u00bc \u00f0c 0 ; l\u00de. There are two commonly use methods to estimate the exponential growth rate l:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "1. Nonlinear least square to fit to f \u00f0t; c 0 ; l\u00de \u00bc c 0 e lt directly; 2. Linear least square to fit f\u00f0t i ; lnx i \u00deg to ln f \u00f0t; c 0 ; l\u00de \u00bc lnc 0 \u00fe lt.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "The nonlinear least squares method does not have an analytic solution. Numerical optimization is needed to solve the minimization problem (6). The linear least square method has an analytic solution: Let [ 0 \u00bc lnc 0 , then the least squares problem becomes",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "The objective function is a quadratic function of [ 0 and l, thus, the minimum is achieved at",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "i\u00bc0 y i , which represents the average of any sequence fy i g n i\u00bc0 , then,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "and thus the best fit exponential growth rate ls b l \u00bc",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "Do these two methods yield the same answer? To compare, we simulate an epidemic curve of the stochastic SEIR model in Example 2, using the Gillespie method (Gillespie, 1976) . The simulated daily cases (number of individuals showing symptom on a day) are then aggregated into weekly cases. Then, we use both methods to fit an exponential curve to the simulated epidemic curve. The simulated epidemic curve and the fitting results are shown in Fig. 3 . This exercise illustrates a challenge of fitting an exponential model to an epidemic curve: how to determine the time period to fit the exponential model. The exponential growth rate of an SEIR model decreases with time as the susceptible population decreases. In Fig. 3 , The epidemic curve peaks in week 13. We choose a sequence of nested fitting windows starting in the first week and ending in a week w for w \u00bc 3; 4;\u2026;13. The SEIR model has an asymptotic exponential growth, so the fitted exponential growth rate is not monotonic near the beginning of the epidemic. For larger fitting windows, both methods give an exponential growth rate that decreases with the length of the fitting window. We need more data points to reduce the influence of the stochasticity. However, using more data points also risks of obtaining an estimate that deviates too much from the true exponential growth rate. There is no reliable method to choose a proper fitting window. Fig. 3 also shows that the linear and nonlinear least squares methods may not yield the same estimate. This is because of a major limitation of both least squares methods: they implicitly assume that the deviations jx i \u00c0 f \u00f0t i ; q ! \u00dej carry identical weights. With the nonlinear method, later data points (at larger times) deviate more from the exponential curve than the earlier data points, because the exponential growth slows down with time. Thus, the method is more biased to the later data points. With the linear method, the deviations in lnx i are more even than in x i , and thus the linear method is less biased to the later data points than the nonlinear method does.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 173,
                    "text": "(Gillespie, 1976)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [
                {
                    "start": 443,
                    "end": 449,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 716,
                    "end": 722,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 1413,
                    "end": 1419,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Least squares estimation"
        },
        {
            "text": "The least squares method, as mentioned above, is a mathematical problem. It does not explicitly assume any error distributions, and thus cannot give us statistical information about the inference. For example, if we use two slightly different fitting windows and get two slightly different estimates, is the difference of the two estimates statistically significant? Such a question cannot easily be answered by the least squares method. Interestingly, the least squares methods make many implicit assumptions to the deviations. We have mentioned the implicit equal-weight assumption above. It also implicitly assumes that the order of the observations does not matter, and that positive and negative deviations are equivalent. Thus, they implicitly assume that the deviations are independently identically and symmetrically distributed. In statistics, the least squares method is commonly used in linear and nonlinear regression with an addition assumption that the errors are independently and identically normally distributed. However, these assumption on the errors may not be appropriate. For example, the new cases at time t \u00fe 1 may be infected by those who are infected at time t. Thus, the number of new cases at different times may not be independent. Also, the number of cases is a counting variable, and thus its mean and variance may be closely related, meaning that the error may not be identically normally distributed. In the next section, we address some of these problems using the maximum likelihood method.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Least squares estimation"
        },
        {
            "text": "The maximum likelihood method is a commonly used statistical method for parameter inference; see, e.g., [(Bolker, 2008 To construct the likelihood function we need to make assumptions on the error distribution. There are two types of error: the process error and the observation error. The observation error is the error in the observation process. For example, most people with influenza do not go to see a doctor, and thus there is no record of these cases, resulting in an under-reporting of the number influenza cases. Also, many influenza related deaths are caused by complications such as pneumonia, and influenza may not be recorded as the cause. Typos, miscommunication, etc, can all result in observation errors. The process error originates from the stochasticity of the system that is independent to observation. For example, the disease dynamics is Fig. 3 . The simulated SEIR epidemic curve (upper) and the fitted exponential growth rate as a function of the end of the fitting window (lower). The epidemic curve is simulated stochastically from the SEIR model in Example 2 using the Gillespie method (Gillespie, 1976) with the parameters b \u00bc 0:3, s \u00bc 1, g \u00bc 0:2,",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 118,
                    "text": "[(Bolker, 2008",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1114,
                    "end": 1131,
                    "text": "(Gillespie, 1976)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [
                {
                    "start": 861,
                    "end": 867,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Maximum likelihood estimation"
        },
        {
            "text": "The rates have a time unit of a day. The daily cases are then aggregated by week. The data points are taken at times t i \u00bc i, i \u00bc 0; 1; 2; \u202613 weeks. The theoretical exponential growth rate is l \u00bc 0:547 per week.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Maximum likelihood estimation"
        },
        {
            "text": "intrinsically stochastic. The time that an infectious individual recovers, and the time that a susceptible individual is infected, are all random variables that affects the number of new infections at any time, even if we eliminate all observation errors. These two types of errors have very different nature, and thus need very different assumptions. For example, it is reasonable to assume that observation errors are independent to each other, but process errors at a later time are commonly dependent on the process errors at earlier times.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Maximum likelihood estimation"
        },
        {
            "text": "If observation errors are large and process errors are negligible, then we assume that the random variable X i corresponding to the observation x i is independently distributed with a probability mass function p i \u00f0k; q ! \u00de where k is the values that X i can take. Then, the likelihood function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "The maximization of this likelihood function rarely has an analytic solution, and commonly needs to be solved numerically. Note that each factor (probability) can be very small, and thus the product may be very difficult to minimize numerically because of rounding errors (from the binary representation of real numbers in computers). It is a common practice to maximize the log-likelihood function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "For example, we assume that the number of cases x\u00f0t i \u00de at time t i is independently Poisson distributed with mean m i \u00bc c 0 e lti . Then, the log-likelihood function",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "Note that the observed cases x i are constants, and thus the last term can be ignored for maximization. Thus,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "This maximization problem can only be solved numerically. We choose Poisson distribution because its simple form greatly simplifies the log-likelihood function. In addition, it does not introduce more parameters, which is valuable to avoid over-fitting when the number of data points available is small. If the process error is not completely negligible, then choosing an overly dispersed distribution, such as the negative binomial distribution may be desirable. A negative binomial distribution has two parameters, the success probability q ! 0 and the shape parameter r > 0. For simplicity, we assume that the shape parameter r is the same at each time t i , and will; be estimated together with the model parameters q ! ; but q depend on t i . The probability mass function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "and the log-likelihood function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "Again, the last term can be ignored for the optimization problem. In addition, there is a constraint r > 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 1: process errors are negligible"
        },
        {
            "text": "If process errors are large and observation errors are negligible, then we cannot assume that the observed values X i\u00fe1 and X i are independent to each other. Instead, for all i \u00bc 0; 1; \u2026; n \u00c0 2, we compute the probability mass function of X i\u00fe1 given fX j \u00bc x j g i j\u00bc0 , namely, q i\u00fe1 \u00f0k; q ! fx j g i j\u00bc0 \u00de. Then, the likelihood function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 2: observation errors are negligible"
        },
        {
            "text": "For simplicity, assume that X i\u00fe1 is Poisson distribution with mean m i\u00fe1 \u00bc X i e l\u00f0ti\u00fe1\u00c0ti\u00de . Note that, since we assumed no observation error, the initial condition c 0 \u00bc x 0 is exact, and thus there is a single parameter l for the model. Thus,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 2: observation errors are negligible"
        },
        {
            "text": "and thus the log-likelihood function is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 2: observation errors are negligible"
        },
        {
            "text": "x i\u00c01 e l\u00f0t i \u00c0t i\u00c01 \u00de \u00fe x i l\u00f0t i \u00c0 t i\u00c01 \u00de \u00fe x i lnx i \u00c0 lnx i !:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 2: observation errors are negligible"
        },
        {
            "text": "Again, the last two terms can be ignored in maximization because they are constants. Thus, l \u00bc argmax l x i\u00c01 e l\u00f0t i \u00c0t i\u00c01 \u00de \u00fe \u00f0t i \u00c0 t i\u00c01 \u00dex i l:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 2: observation errors are negligible"
        },
        {
            "text": "It is much harder to formulate the likelihood function if process errors and observation errors must both be considered. We can simplify the problem by ignoring the process error and use an overly dispersed observation error distribution as a compensation. Note that this simplification mainly affects the confidence intervals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Case 3: consider both type of errors together"
        },
        {
            "text": "The maximum likelihood method gives a point estimate, i.e., one set of parameter values that makes it mostly likely to observe the data. However, it is not clear how close the point estimates are to the real values. To answer this question we use an interval estimate, commonly known as a confidence interval. A confidence interval with a confidence level a is an interval that has a probability a that contains the true parameter value. A commonly used confidence level is 95%, which originates from a normal distribution. If a random variable X is normally distributed with a mean m and a standard deviation s, then the probability that X2\u00bdm \u00c02s; m \u00fe2s is 95%.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Confidence intervals"
        },
        {
            "text": "The confidence interval can be estimated using the likelihood ratio test [ (Bolker, 2008), p.192] . Let c q !^b e the point estimate of the parameters. A value l 0 is in the 95% confidence interval is equivalent to accepting with 95% probability that l 0 is a possible growth rate. To determine this we fit a nested model by fixing the growth rate l \u00bc l 0 , suppose its point estimate is b q 0 .",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 97,
                    "text": "(Bolker, 2008), p.192]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Confidence intervals"
        },
        {
            "text": "We then compute the likelihood ratio",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Confidence intervals"
        },
        {
            "text": "The Wilks' theorem (Wilks, 1938) guarantees that, as the sample size becomes large, the statistics \u00c02lnL \u00bc 2\u00bd[\u00f0 b q\u00de \u00c0[\u00f0 b q 0 \u00de is c 2 distributed with a degree of freedom 1. We thus can compare \u00c02lnL with the 95% quantile of the c 2 distribution and determine if l 0 should be in the confidence interval or not. We can thus perform a linear search on both sides of the point estimate to determine the boundary of the confidence interval.",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 32,
                    "text": "(Wilks, 1938)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Confidence intervals"
        },
        {
            "text": "We still have not addressed the problem of choosing a fitting window for an exponential model. Recall that the challenge arises because the exponential growth rate of an epidemic decreases with time. Instead of finding heuristic conditions for choosing the fitting window, we circumvent this problem by incorporating the decrease of the exponential growth rate into our model. We have two choices, using either a mechanistic model such as an SIR or SEIR model, or a phenomenological model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mechanistic and phenomenological models"
        },
        {
            "text": "Naturally, if we know that a mechanistic model is a good description of the disease dynamics, fitting such a model to the epidemic curve is a good option (see, e.g., (Chowell, Ammon, Hengartner, & Hyman, 2006; Pourabbas, d'Onofrio, & Rafanelli, 2001) ,). We use an SIR model as an example. For simplicity, we assume that the process error is negligible, and the incidence rate is Poisson distributed with a mean C\u00f0t\u00de given by an SIR model (C\u00f0t\u00de \u00bc bSIN where N is the population size). To construct the log-likelihood function, we need to calculate C\u00f0t\u00de, i.e., numerically solve the SIR model. To do so, we need the transmission rate b. the recovery rate g, the initial fraction of infectious individuals I\u00f00\u00de \u00bc I 0 (with the assumption that R\u00f00\u00de \u00bc 0, S\u00f00\u00de \u00bc 1 \u00c0 I 0 , and thus I 0 determines the initial conditions), in addition to the population size N. Thus, the parameters of the model is q ! \u00bc \u00f0b; g; I 0 ; N\u00de. Thus the log-likelihood function is (ignoring the constant terms)",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 209,
                    "text": "(Chowell, Ammon, Hengartner, & Hyman, 2006;",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 210,
                    "end": 250,
                    "text": "Pourabbas, d'Onofrio, & Rafanelli, 2001)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Mechanistic models"
        },
        {
            "text": "where the number of new cases c\u00f0t i \u00de in the time interval \u00bdt i ; t i\u00fe1 is c\u00f0t i \u00de \u00bc S\u00f0t i\u00fe1 \u00de \u00c0 S\u00f0t i \u00de ;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mechanistic models"
        },
        {
            "text": "and S\u00f0t i \u00de is solved numerically from the SIR model. Thus, [ implicitly depend on b, g and I 0 through S\u00f0t\u00de.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mechanistic models"
        },
        {
            "text": "One draw back using such a mechanistic model is its high computational cost, since each evaluation of the log-likelihood function requires solving the model numerically, and numerical optimization algorithms can be very hungry on function evaluations, especially if the algorithm depends on numerical differentiation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mechanistic models"
        },
        {
            "text": "Another draw back is that these mechanistic models can be overly simplified, and may not be a good approximation to the real disease dynamics. For example, for seasonal influenza, due to the fast evolution of the influenza virus, individuals have different history of infection, and thus have different susceptibility to a new strain. Yet simple SIR and SEIR models assume a population with a homogeneous susceptibility. Thus using a simple SIR to fit to an influenza epidemic may be an over simplification. However, realistic mechanistic models can be overly complicated, and involve too many parameters that are at best difficult to estimate. For example, a multi-group SIR model depends on a contact matrix consisting of transmission rates between groups, which contains a large number of parameters if the model uses many groups.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mechanistic models"
        },
        {
            "text": "If all we need to estimate is the exponential growth rate, we only need a model that describes the exponential growth that gradually slows down. Most cumulative epidemic curves grow exponentially initially, and then saturates at the final epidemic size. A simple phenomenological model can be used to describe the shape of the cumulative epidemic curve, but the model itself may not have realistic biological meaning. However, if simple mechanistic models cannot faithfully describe the epidemic process, using a simple phenomenological model with an analytical formula may be a better choice, at least numerically, because repetitively solving a system differential equations numerically, and differentiating the log-likelihood function numerically, can both be avoided with the analytical formula. Here we discuss some examples for such models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Phenomenological models"
        },
        {
            "text": "The logistic model is the simplest model that shows an initial exponential growth followed a gradual slowing down and a saturation. The cumulative incidences C\u00f0t\u00de (the total number of cases by time t) can be approximated by d dt",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Logistic model"
        },
        {
            "text": "C\u00f0t\u00de \u00bc rC\u00f0t\u00de 1 \u00c0 C\u00f0t\u00de K :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Logistic model"
        },
        {
            "text": "where r is the exponential growth rate, and K \u00bc lim t/\u221e C\u00f0t\u00de. Let C 0 \u00bc C\u00f00\u00de, its solution is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Logistic model"
        },
        {
            "text": "The new cases c\u00f0t i \u00de in a time period \u00bdt i ; t i\u00fe1 is thus",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Logistic model"
        },
        {
            "text": "The model parameters are q ! \u00bc \u00f0r; K; C 0 \u00de. Note that it is less than the number of parameters of the simplest mechanistic model (i.e., the SIR model).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Logistic model"
        },
        {
            "text": "The logistic model has a fixed rate of slowing down of the exponential growth rate. To be more flexible, we can use the Richards model (Richards, 1959) for the cumulative incidence curve. The Richards model, also called the power law logistic model, can be written as d dt",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 151,
                    "text": "(Richards, 1959)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Richards model"
        },
        {
            "text": "C\u00f0t\u00de",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Richards model"
        },
        {
            "text": "where ais the parameter that controls the steepness of the curve. Note that the logistic model is a special case with a \u00bc 1. Its solution is The new cases c\u00f0t i \u00de in a time period \u00bdt i ; t i\u00fe1 is also given by (8). The parameters are q ! \u00bc \u00f0r; K; C 0 ; a\u00de.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Richards model"
        },
        {
            "text": "To compare the performance of both the SIR model and the phenomenological models, we fit these models to the stochastically simulated SEIR epidemic curve of weekly cases that we introduced in Section 3 (Fig. 3) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 202,
                    "end": 210,
                    "text": "(Fig. 3)",
                    "ref_id": null
                }
            ],
            "section": "Comparison of the models"
        },
        {
            "text": "We assume that the process error is negligible, and the observations are Poisson distributed about the mean that is given by the corresponding models. We use the maximum likelihood method. The results are shown in Fig. 4 . The predictions of the exponential model, as discussed before, quickly decreases as more data points are used. Both the logistic model and the Richards model give robust estimates with fitting windows ending up to the peak of the epidemic. The SIR model gives a robust estimate for all fitting windows up to the whole epidemic curve.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 214,
                    "end": 220,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Comparison of the models"
        },
        {
            "text": "Thus, the SIR model is a good model to use to fit the exponential growth rate, even if it may not be the correct mechanistic model. (e.g., it ignores the latent period in this example). It requires more computational power, because the epidemic curve lacks an analytic formula, and needs to be numerically solved from a system of ordinary differential equations. The logistic model and the Richards model can be used for all data points up to the peak of the epidemic. Fig. 4 also show that the SIR model and the logistic model give the narrowest confidence intervals. However, narrower confidence intervals may not be desirable if it has a large chance that it does not contain the true value. Due to errors, especially process errors, each realization of the underlying stochastic epidemic process yields a different epidemic curve. These epidemic curves may exhibit different exponential growth rates even if the underlying parameter values are the same. An observed epidemic curve is just a single realization of the epidemic process. Does the estimated confidence intervals contain the theoretical exponential growth rate of the epidemic process? This question is answered by the \"coverage probability\", which is the probability that the confidence interval contains the true value. If the confidence interval properly considers all sources of stochasticity, then the coverage probability should be equal to its confidence level.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 469,
                    "end": 475,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Comparison of the models"
        },
        {
            "text": "To illustrate this, we numerically compute the coverage of the confidence intervals by simulating the SEIR model 400 times and compute confident interval of the exponential growth rate for each realization, and compute the fraction of the confident intervals containing the theoretical value l \u00bc 0:537. The results is summarized in below: logistic model Richards model coverage probability 43% 65%",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Coverage probabilities"
        },
        {
            "text": "That is, even though the logistic model gives a narrow confidence interval, its coverage probability is low. The coverage probability of the confidence interval given by the Richards model is also significantly lower than the confidence level. This is indeed caused by treating process errors as observation errors. If there is under reporting, that is, only a fraction p of the cases can be observed, then the observation error becomes larger as p decreases (i.e., more under reporting). The coverage will become larger as a result. For example, the case fatality ratio of the 1918 pandemic influenza is about 2% (Frost, 1920) . Thus, the mortality curve can be treated as the epidemic curve with a large under reporting ratio, and thus the observation error dominates. In this case ignoring the process error is appropriate.",
            "cite_spans": [
                {
                    "start": 614,
                    "end": 627,
                    "text": "(Frost, 1920)",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Coverage probabilities"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Ecological models and data in R",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Bolker",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Transmission dynamics of the great influenza pandemic of 1918 in geneva, Switzerland: Assessing the effects of hypothetical interventions",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chowell",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "E"
                    ],
                    "last": "Ammon",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "W"
                    ],
                    "last": "Hengartner",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Hyman",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Journal of Theoretical Biology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Statistics of influenza morbidity. with special reference to certain factors in case incidence and case-fatality",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Frost",
                    "suffix": ""
                }
            ],
            "year": 1920,
            "venue": "Public Health Reports",
            "volume": "35",
            "issn": "",
            "pages": "584--597",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A general method for numerically simulating the stochastic time evolution of coupled chemical reactions",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "T"
                    ],
                    "last": "Gillespie",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "Journal of Computational Physics",
            "volume": "22",
            "issn": "",
            "pages": "403--434",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A method to estimate the incidence of communicable diseases under seasonal fluctuations with application to cholera",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dushoff",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Bolker",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J D"
                    ],
                    "last": "Earn",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Pourabbas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Onofrio",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rafanelli",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Applied Mathematics and Computation",
            "volume": "76",
            "issn": "",
            "pages": "161--174",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "A flexible growth function for empirical use",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "J"
                    ],
                    "last": "Richards",
                    "suffix": ""
                }
            ],
            "year": 1959,
            "venue": "Journal of Experimental Botany",
            "volume": "10",
            "issn": "",
            "pages": "290--300",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "How generation intervals shape the relationship between growth rates and reproductive numbers",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wallinga",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lipsitch",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proceedings of the Royal Society B: Biological Sciences",
            "volume": "274",
            "issn": "",
            "pages": "599--604",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Different epidemic curves for severe acute respiratory syndrome reveal similar impacts of control measures",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wallinga",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Teunis",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "American Journal of Epidemiology",
            "volume": "160",
            "issn": "",
            "pages": "509--516",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "The comparison of the results of fitting the SIR, exponential, logistic, and Richards models to a simulated weekly incidence curve, as a function of the end point of the fitting window (upper). The epidemic curve (lower) is shown as a reference. The epidemic curve and the theoretical exponential",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Wilks",
                    "suffix": ""
                }
            ],
            "year": 1938,
            "venue": "Annals of Mathematical Statistics",
            "volume": "9",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Consider the following Susceptible-Infectious-Recovered (SIR) model: E-mail address: junlingm@uvic.ca. Peer review under responsibility of KeAi Communications Co., Ltd. //doi.org/10.1016/j.idm.2019.12.009 2468-0427/\u00a9 2019 The Authors. Production and hosting by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Cumulative Ebola cases during the 2014e16 western African Ebola outbreak, plotted in linear scale (left) and log-linear scale (right). Source: Center for Disease Control Ebola case counts (Center for Disease Control, 2016).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Weekly influenza mortality during the 1918 pandemic in Philadelphia, plotted in linear scale (left) and log-linear scale (right).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Lets consider the SEIR model(3)in Example 2. The basic reproduction number is R 0 \u00bc b=g. To link R",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "170]. It relies on a \"likelihood function\" L\u00f0 q ! \u00de where q ! is the vector of parameters. The likelihood function is a function proportional to the conditional probability of observing the data points f\u00f0t i ; x i \u00deg n\u00c01 i\u00bc0 given the parameters qWe choose the parameter values that maximize the likelihood, i.e.,",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "This research is partially supported by a Natural Sciences and Engineering Research Council Canada discovery grant, and National Natural Science Foundation of China (No.11771075).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements"
        }
    ]
}